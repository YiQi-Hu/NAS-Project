{
    "conv":{
        "filter_size":{
            "val": [16,21,24,32,48,64,80,96,112,128,144,160,192,208,224,256,288,320,352,384,448,
            512,640,728,896,1000,1024,1056,1154,1536,2048,4096],
            "pros": [
                [0.001, 0.003],
                [0.0005, 0.002],
                [0.0005,0.002],
                [0.1,0.2],
                [0.01,0.1],
                [0.03,0.1],
                [0,0.001],
                [0.01,0.03],
                [0,0.002],
                [0.1,0.35],
                [0,0.001],
                [0.005,0.025],
                [0.005,0.21],
                [0,0.001],
                [0.005,0.03],
                [0.05,0.15],
                [0,0.001],
                [0,0.01],
                [0,0.002],
                [0,0.025],
                [0,0.003],
                [0,0.06],
                [0,0.001],
                [0,0.033],
                [0,0.001],
                [0,0.001],
                [0.01,0.051],
                [0,0.001],
                [0,0.006],
                [0,0.002],
                [0,0.009]
            ]
        },
        "kernel_size":{
            "val": [1, 3, 5, 7, 11, 32],
            "pros": [
                [0.3, 0.6],
                [0.2, 0.55],
                [0.005,0.019],
                [0.005,0.015],
                [0.005,0.015]
            ]
        },
        "activation":{
            "val": ["relu", "leakyrelu"],
            "pros": [
                [0.7, 0.9]
            ]
        }
    },
    "pooling":{
        "pooling_type":{
            "val": ["avg", "max","global"],
            "pros": [
                [0.2, 0.5],
                [0.3,0.6]
            ]
        },
        "kernel_size":{
            "val": [2, 3, 6,7,8],
            "pros": [
                [0.1, 0.25],
                [0.3, 0.55],
                [0.001,0.007],
                [0.03,0.09]
            ]
        }
    },
    "dense":{
        "layer_size":{
            "val": [1, 2],
            "pros": [
                [0.4, 0.6]
            ]
        },
        "neural_size":{
            "val": [10, 20, 30],
            "pros": [
                [0.1, 0.2],
                [0.1, 0.3]
            ]
        },
        "activation":{
            "val": ["relu", "sigmoid", "tanh", "identity"],
            "pros": [
                [0.7, 0.9],
                [0.1, 0.2],
                [0.3, 0.7]
            ]
        }

    },
    "pros": [
        [0.7, 0.92]
    ]
}